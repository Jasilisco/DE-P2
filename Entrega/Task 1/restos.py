    

def unique_column_values(csv_path, column_name):
    """
    Lee un CSV y devuelve un set con todos los valores distintos de la columna,
    incluyendo None y NaN.
    """
    df = pd.read_csv(csv_path)
    
    if column_name not in df.columns:
        raise ValueError(f"La columna '{column_name}' no existe en el CSV")
    
    # Obtenemos los valores únicos
    unique_vals = df[column_name].unique()
    
    # Convertimos a set y normalizamos NaN y None
    result = set()
    for val in unique_vals:
        if pd.isna(val):
            result.add(float('nan'))  # o 'NaN' si quieres representarlo como string
        else:
            result.add(val)
    
    return result

def mergeCSV(file1, file2, chunksize, mergeLogic, rename= {}, resultSuffix='general'):
    file1DF = pd.read_csv(file1, low_memory=False)
    output_file = f"result_{resultSuffix}.csv"
    for field, renamedField in rename.items():
        file1DF = file1DF.rename(columns={field: renamedField})

    for i, chunk in enumerate(pd.read_csv(file2, chunksize=chunksize, low_memory=False)):
        
        merged = chunk.merge(
            file1DF,
            left_on=mergeLogic.get("base"),
            right_on=mergeLogic.get("field"),
            how="inner",
            suffixes= ("_old", None)
        )
        
        mode = "w" if i == 0 else "a" 
        header = i == 0
        merged.to_csv(output_file, mode=mode, header=header, index=False)

    os.remove(file2)
    print(f"Merge completado. Archivo guardado en {output_file}")
    return output_file

def nans(csv_path, column_name):
    """
    Lee un CSV y devuelve un set con todos los valores distintos de la columna,
    incluyendo None y NaN. Además, imprime las filas donde el valor sea NaN.
    """
    df = pd.read_csv(csv_path)
    
    if column_name not in df.columns:
        raise ValueError(f"La columna '{column_name}' no existe en el CSV")
    
    # Inicializamos set de valores únicos
    result = set()
    
    # Iteramos sobre la columna
    for idx, val in df[column_name].items():
        if pd.isna(val):
            #print(f"[NaN] Fila {idx}: {df.iloc[idx].to_dict()}")
            result.add(float('nan'))  # Representamos NaN de manera consistente
        else:
            result.add(val)
    
    return result

def generateId(*args):
    raw = "-".join(str(a) for a in args)
    return hashlib.sha256(raw.encode()).hexdigest()

def split_date(date_str, param):
    if pd.isna(date_str):
        return None, None, None
    try:
        dt = pd.to_datetime(date_str, errors="coerce", dayfirst=True)
        if pd.isna(dt):
            return None, None, None        
        elif param == "year":
            return int(dt.year)
        elif param == "month":
            return int(dt.month)
        elif param == "day":
            return int(dt.day)
        elif param == "DayOfTheWeek":
            return dt.weekday() + 1
        else:
            return int(dt.year), int(dt.month), int(dt.day)
    except Exception:
        return None, None, None
    
def mapDimensionsS(dataFrame, result):
    for _, row in dataFrame.iterrows():
        for table in result:
            record = extractRecord(table, row)
            if isinstance(cfg.design[table], dict):
                hashBase = {key: record[key] for key in cfg.design[table].get("hash", {}).get("base", [])}
                for _, rules in cfg.design[table].items():
                    if isinstance(rules, dict):
                        record[rules.get("mapping", '')] = generateId(hashBase)
            result[table].append(record)
    return result

def extractRecord(table, row):
    record = {}
    for col_name, rules in cfg.tables[table].items():
        if isinstance(rules, dict):
            if rules.get("autogenerated", False):
                continue
            csv_col = rules.get("value", "")
            is_date = rules.get("date", False)
            is_day = rules.get("day", False)
        else:
            csv_col = rules
            is_date = False
            is_day = False
        value = row.get(csv_col, None)  
        if is_date:
            record[col_name] = splitDate(value, col_name.lower())
        elif is_day:
            record[col_name] = getDayOfWeek(value)
        else:
            record[col_name] = value   
    return record

def obtainForeignKey(fk, row, dimension):
    if fk not in dimension:
        return None
    table_data = dimension[fk]
    conditions = extractRecord(fk, row)
    for record in table_data:
        if all(record.get(col) == val for col, val in conditions.items()):
            return record.get(cfg.idMapping[fk], None)
    return None

def mapFact(df, result, dimension):
    for table, table_cfg in cfg.tables.items():
        records = pd.DataFrame(index=df.index)
        for col_name, rules in table_cfg.items():
            if isinstance(rules, dict):
                if rules.get("autogenerated", False):
                    continue  
                mapping = rules.get("mapped", False)
                fk = rules.get("fk", False)
            else:
                mapping = rules
                fk = False

            if mapping:
                records[col_name] = df.get(mapping)
            elif fk:
                records[col_name] = df.apply(lambda row: obtainForeignKey(fk, row, dimension), axis=1)
            else:
                records[col_name] = None

        if table not in result:
            result[table] = []

        result[table].extend(records.to_dict(orient="records"))
    return result

def insertData(data):
    try:
        engine = get_connection()
        metadata = alc.MetaData()
        with engine.begin() as conn:
            inspector = alc.inspect(conn)    

            for table_name in inspector.get_table_names():
                if table_name in data:
                    print(f"Inserting values in table {table_name}")
                    table = alc.Table(table_name, metadata, autoload_with=conn)

                    values = data[table_name]
                    if isinstance(values, dict):
                        values = [values]

                    for row in values:
                        row_clean = clean(row)
                        stmt = alc.insert(table).values(row_clean)
                        #stmt = stmt.prefix_with("IGNORE")
                        conn.execute(stmt)

        engine.dispose()
        print("All data inserted")

    except Exception as ex:
        print(f"An error occurred: {ex}")    